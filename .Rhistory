summarize(by_package,mean(size))
play()
?n
?n_distinct
nxt()
submit()
submit
submit()
pack_sum
quantile(pack_sum$count,probs = 0.99)
top_counts<- filter(pack_sum,count > 679)
top_counts
View(top_counts)
top_counts_sorted <- arrange(top_counts,desc(count))
View()
View(top_counts_sorted)
quantile(pack_sum$unique,probs=0.99)
top_unique <- filter(pack_sum,unique > 465)
View(top_unique)
top_unique_sorted <- arrange(top_unique,desc(unique))
View(top_unique_sorted)
submit()
submit()
submit()
View(result3)
submit()
submit()
submit()
submit()
library(tidyr)
students
?gather
gather(students,sex,count,-grade)
students2
gather(students2,key="sex_class",value = "count")
gather(students2,sex_class,count, -grade)
res<-gather(students2,sex_class,count, -grade)
res
?separate
separate(res,col=sex_class,into=c("sex","class"))
submit()
students3
submit()
?spread
submit()
submit()
submit
submit()
submit()
submit()
library(readr)
parse_number("class5")
submit()
students4
submit()
submit()
submit()
passed
failed
submit()
submit()
reset()
swirl()
passed <- passed %>% mutate(status = "passed")
failed <- failed %>% mutate(status = "failed")
bind_rows(passed,failed)
sat
play()
?contains
?separate
nxt()
submit()
submit()
submit()
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv","./data/wk3.csv")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv","./wk3.csv")
dat_df<- read.csv("./wk3.csv")
summary(dat_df)
summarize(dat_df)
str(dat_df)
?select
?filter
agricultureLogical <- dat_df[dat_df$ACR == 3 & dat_df$AGS == 6]
agricultureLogical <- dat_df$ACR == 3 & dat_df$AGS == 6
agricultureLogical
which(agricultureLogical)
install.packages("jpeg")
library(jpeg)
jeff<-readJPEG("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg")
jeff<-readJPEG("https://d396qusza40orc.cloudfront.net/getdata/jeff.jpg")
jeff<-readJPEG("http://d396qusza40orc.cloudfront.net/getdata/jeff.jpg")
jeff<-readJPEG("http://d396qusza40orc.cloudfront.net/getdata/jeff.jpg")
?readJPEG
jeff<-readJPEG("http://d396qusza40orc.cloudfront.net/getdata/jeff.jpg",native=FALSE)
jeff<-readJPEG("http://d396qusza40orc.cloudfront.net/getdata/jeff.jpg",native=TRUE)
download.file("http://d396qusza40orc.cloudfront.net/getdata/jeff.jpg","./jeff.jpg")
jeff<-readJPEG("./jeff.jpg",native=TRUE)
quantile(jeff,probs = c(0.3,0.8))
download.file("https://d396qusza40orc.cloudfront.net/getdata/jeff.jpg","./jeff.jpg")
jeff<-readJPEG("./jeff.jpg",native=TRUE)
quantile(jeff,probs = c(0.3,0.8))
gdp <- read.csv("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv")
edu <-read.csv("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv")
rm(dat_df)
head(gdp)
head(edu)
str(edu)
str(gdp)
?
merge
merge(gdp,edu,by = "Gross.domestic.product.2012" ,by.x = "X", by.y = "CountryCode")
res<- merge(gdp,edu,by = "Gross.domestic.product.2012" ,by.x = "X", by.y = "CountryCode")
tail(res)
res<- merge(gdp,edu,by = "Gross.domestic.product.2012" ,by.x = "X", by.y = "CountryCode",sort = TRUE)
tail(res)
res<- merge(gdp,edu,by.x = "X", by.y = "CountryCode")
nrow(res)
res<- merge(gdp,edu,by = "CountryCode")
res<- merge(gdp,edu,by.x = "X", by.y = "CountryCode",incomparables = NA)
nrow(res)
gdp
gdp <- gdp(5:)
gdp <- gdp[5:]
gdp[5]
gdp <- read.csv("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv",skip = 4)
gdp
tail(res)
tail(gdp,10)
gdp <- gdp$X ! = ""
gdp <- gdp$X != ""
gdp <- read.csv("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv",skip = 4)
gdp <- filter(gdp,X!= "")
gdp
tail(gdp,10)
gdp <- select(gdp,c(1,2,4,5))
gdp
colnames(gdp) <- c("CountryCode","Rank","Economy","GDP")
head(gdp,10)
merged <- merge(gdp,edu,by = "CountryCode")
merged
nrow(merged)
merged <- merge(gdp,edu,by = "CountryCode",all = FALSE)
nrow(merged)
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
f <- file.path(getwd(), "GDP.csv")
download.file(url, f)
dtGDP <- data.table(read.csv(f, skip=4, nrows=215))
dtGDP <- dtGDP[X != ""]
dtGDP <- dtGDP[, list(X, X.1, X.3, X.4)]
library(data.table)
View(by_package)
View(by_package)
View(by_package)
rm(by_package)
rm(cran)
rm(cran2)
rm(cran3)
rm(df)
rm(failed)
rm(gradebook)
rm(pack_sum)
rm(passed)
rm(result1)
rm(result2)
rm(result3)
rm(sat)
rm(student_info)
rm(students)
rm(students2)
rm(students3)
rm(students4)
rm(top*)
rm(top_countries)
rm(top_counts)
rm(top_counts_sorted
)
rm(top_unique)
rm(top_unique_sorted)
rm(f)
rm(csv_url)
rm(con)
rm(htmlCode)
rm(agricultureLogical)
rm(my_div)
rm(my_seq)
rm(my_sqrt)
rm(path2csv)
rm(url)
rm(web_url)
rm(x,y,z)
merged <- merge(gdp,edu,by='CountryCode',all = FALSE)
nrow(merged)
head(merged)
sum(!is.na(unique(merged$Rank)))
arrange(merged,desc(Rank))
merged <- merge(gdp,edu,by='CountryCode',all = TRUE)
nrow(merged)
sum(!is.na(unique(merged$Rank)))
merged <- merge(gdp,edu,by=c("CountryCode"),all = TRUE)
nrow(merged)
sum(!is.na(unique(merged$Rank)))
merged
arrange(merged,desc(Rank))
tail(arrange(merged,desc(Rank)))
gdp <- read.csv("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv",skip = 4,nrows = 190)
gdp
gdp<-select(gdp,c(1,2,4,5))
colnames(gdp) <- c("CountryCode","Ranking","LongName","GDP")
head(gdp)
merged <- merge(gdp,edu,by=c("CountryCode"),all = FALSE)
nrow(merged)
sum(!is.na(unique(merged$Rank)))
arrange(merged,desc(Rank))
arrange(merged,desc(Ranking))
library(dplyr)
grouped<- group_by(merged,Income.Group)
grouped
avgRank<- summarize(grouped,avgGDP = mean(Ranking))
avgRank
quantile(merged$Ranking, probs = seq(0,1,.2))
library(Hmisc)
install.packages(Hmisc)
install.packages("Hmisc")
library(Hmisc)
?cut2
merged
cutGDP <- cut2(merged,g=5)
cutGDP <- cut2(merged$Ranking,g=5)
cutGDP
table(cutGDP,arrange(merged,desc(Ranking)))
table(cutGDP,arrange(merged,desc(Ranking))$Income.Group)
cutGDP <- cut(merged$Ranking,breaks = 5)
cutGDP
table(cutGDP,arrange(merged,desc(Ranking))$Income.Group)
filter(merged,Ranking > 152, Income.Group == "Lower middle income")
filter(merged,Ranking = 190, Income.Group == "Lower middle income")
filter(merged,Ranking == 190, Income.Group == "Lower middle income")
table(cutGDP,arrange(merged,desc(Ranking))$Income.Group)
quantile(merged$Ranking, probs = seq(0,1,.2))
breaks <- quantile(merged$Ranking, probs = seq(0,1,.2))
merged$QuantileGDP <-cut(merged[,"Ranking"],breaks = breaks)
merged
merged['Income.Group' == "Lower middle income",.N,by= c("Income.Group","QuantileGDP")]
merged
merged$QuantileGDP <-cut(merged$Ranking,breaks = 5)
merged
table(merged$QuantileGDP,merged$Income.Group)
cutGDP <- cut(merged$Ranking,breaks = 5)
table(cutGDP,merged$Income.Group)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg","./jeff.jpg",mode = "wb")
jeff<-readJPEG("./jeff.jpg",native = TRUE)
quantile(jeff,probs=c(0.3,.8))
library(swirl)
swirl()
Sys.getlocale("LC_TIME")
library(lubridate)
help(package="lubridate")
help(package=lubridate)
this_day <- today()
this_day
month(this_day)
wday(this_day)
wday(this_day,label = TRUE)
this_moment <- now()
this_moment
second(this_moment)
my_date<-ymd("1989-05-17")
my_date
class(my_date)
ymd("1989 May 17")
mdy("March 12,1975")
mdy("March 12, 1975")
dmy(25081985)
ymd("192012")
ymd("1920-1-2")
dt1
ymd_hms(dt1)
hms("03:22:14")
dt2
ymd(dt2)
update(this_moment,hours=8,minutes = 34,seconds=55)
this_moment
this_moment<-update(this_moment,hours=2,minutes = 17)
this_moment
?now
nyc<-now(tzone = "America/New_York")
nyc
depart<-nyc+days(2)
depart
depart<-update(depart,hours = 17, minutes = 34)
depart
arrive<-depart+minutes(50)+hours(15)
?with_tz
with_tz(arrive,tzone = "Asia/Hong_Kong")
arrive<-with_tz(arrive,tzone = "Asia/Hong_Kong")
arrive
last_time<-mdy("June 17, 2008",tz="Singapore")
last_time
?interval
how_long<-interval(last_time,arrive)
as.period(how_long)
stopwatch()
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv","./wk4_1.csv")
wk4dat<-read.csv("./wk4_1.csv")
strsplit(wk4dat,"wgtp")[123]
strsplit(wk4dat,"wgtp")
strsplit(colnames(wk4dat),"wgtp")
strsplit(colnames(wk4dat),"wgtp")[123]
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv","./wk4_2.csv")
wk4dat2<-read.csv("./wk4_2.csv")
head(wk4dat2)
wk4dat2<-read.csv("./wk4_2.csv",skip = 4)
head(wk4dat2)
tail(wk4dat2)
wk4dat2
tail(wk4dat2,10)
tail(wk4dat2,20)
tail(wk4dat2,50)
tail(wk4dat2,100)
wk4dat2<-read.csv("./wk4_2.csv",skip = 4,n=231)
wk4dat2<-read.csv("./wk4_2.csv",skip = 4,nrows = 231)
tail(wk4dat2,10)
as.numeric(gsub(",","",wk4dat2$X.4))
mean(as.numeric(gsub(",","",wk4dat2$X.4)))
mean(as.numeric(gsub(",","",wk4dat2$X.4)),na.rm = TRUE)
wk4dat2<-read.csv("./wk4_2.csv")
mean(as.numeric(gsub(",","",wk4dat2$X.4)),na.rm = TRUE)
wk4dat2<-read.csv("./wk4_2.csv",skip = 4)
mean(as.numeric(gsub(",","",wk4dat2$X.4)),na.rm = TRUE)
wk4dat2<-read.csv("./wk4_2.csv",skip = 4,nrows = 215,stringsAsFactors = FALSE)
wk4dat2<-wk4dat2[X!=""]
colnames(wk4dat2)
gdp<-wk4dat2$X.4
gdp
mean(as.numeric(gsub(",","",gdp)),na.rm = TRUE)
colnames(wk4dat2)
head(wk4dat2)
countryNames <- wk4dat2$X.3
grep("^United",countryNames)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv","./wk4_3.csv")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv","./wk4_3_2.csv")
gdp<-read.csv("./wk4_3.csv")
edu<-read.csv("./wk4_3_2.csv")
gdp
head(gdp)
gdp<-read.csv("./wk4_3.csv",skip = 4,nrows = 190)
head(edu)
merged<-merge(gdp,edu,by.x = "X",by.y = "CountryCode")
merged
head(merged)
isFiscalYr<-grepl("fiscal year end",tolower(merged$Special.Notes))
head(isFiscalYr)
isJune<-grepl("june",tolower(merged$Special.Notes))
table(isFiscalYr,isJune)
install.packages(quantmod)
install.packages("quantmod")
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
sampleTimes
library(lubridate)
ymd(sampleTimes)
sampleT<-ymd(sampleTimes)
is2012<-grepl("2012",year(sampleT))
sum(is2012)
wday(sampleT[1])
isMonday<-grep(2,wday(sampleT))
sum(isMonday)
wday(sampleT[1],label = TRUE)
table(is2012,isMonday)
isMonday<-grepl(2,wday(sampleT))
table(is2012,isMonday)
setwd("~/GitHub/GettingAndCleaningData")
ls
ls()
remove(amzn,avgRank,gdp,edu,merged)
remove(grouped,res,wk4dat,wk4dat2
)
remove(arrive,breaks,countryNames,cutGDP,dt1,dt2,depart)
remove(how_long,is2012,isMonday,isJune,isFiscalYr,jeff,last_time,my_date,nyc)
remove(sampleT,sampleTimes,old.dir,this_day,this_moment)
dir()
run_analysis.r
open("run_analysis.R")
# read train data
X_train <- read.table("./UCI HAR Dataset/train/X_train.txt")
Y_train <- read.table("./UCI HAR Dataset/train/Y_train.txt")
Sub_train <- read.table("./UCI HAR Dataset/train/subject_train.txt")
# read test data
X_test <- read.table("./UCI HAR Dataset/test/X_test.txt")
Y_test <- read.table("./UCI HAR Dataset/test/Y_test.txt")
Sub_test <- read.table("./UCI HAR Dataset/test/subject_test.txt")
#merging datasets
x_total<-rbind(X_train,X_test)
y_total<-rbind(Y_train,Y_test)
sub_total<-rbind(Sub_train,Sub_test)
#read activity_labels
activityLabel<-read.table("./UCI HAR Dataset/activity_labels.txt")
activityLabel[,2]<-as.character(activityLabel[,2])
#read features
features<-read.table("./UCI HAR Dataset/features.txt")
features[,2]<-as.character(features[,2])
wantedFeature<-grep(".*mean.*|.*std.*",features[,2])
wantedFeature
wantedFeature.names<-features[wantedFeature,2]
wantedFeature.names
wantedFeature.names<-gsub("-mean","Mean",wantedFeature)
wantedFeature.names<-gsub("-std","Std",wantedFeature)
wantedFeature.names
wantedFeature<-grep(".*mean.*|.*std.*",features[,2])
wantedFeature.names<-features[wantedFeature,2]
wantedFeature.names
wantedFeature.names<-gsub("-mean","Mean",wantedFeature.names)
wantedFeature.names<-gsub("-std","Std",wantedFeature.names)
wantedFeature.names<-gsub("[-()]","",wantedFeature.names)
wantedFeature.names
#read activity_labels
activityLabel<-read.table("./UCI HAR Dataset/activity_labels.txt")
activityLabel[,2]<-as.character(activityLabel[,2])
#read features
features<-read.table("./UCI HAR Dataset/features.txt")
features[,2]<-as.character(features[,2])
wantedFeature<-grep(".*mean.*|.*std.*",features[,2])
wantedFeature.names<-gsub("-mean","Mean",wantedFeature.names)
wantedFeature.names<-gsub("-std","Std",wantedFeature.names)
wantedFeature.names<-gsub("[-()]","",wantedFeature.names)
# read train data
X_train <- read.table("./UCI HAR Dataset/train/X_train.txt")[wantedFeature]
Y_train <- read.table("./UCI HAR Dataset/train/Y_train.txt")
Sub_train <- read.table("./UCI HAR Dataset/train/subject_train.txt")
train<-cbind(Sub_train,Y_train,X_train)
# read test data
X_test <- read.table("./UCI HAR Dataset/test/X_test.txt")[wantedFeature]
Y_test <- read.table("./UCI HAR Dataset/test/Y_test.txt")
Sub_test <- read.table("./UCI HAR Dataset/test/subject_test.txt")
test<-cbind(Sub_test,Y_test,X_test)
#merge datasets
alldata<-rbind(train,test)
colnames(alldata)<-c("subject","activity",wantedFeature.names)
alldata
head(alldata)
alldata$activity<-factor(alldata$activity,levels = activity[,1],labels = activity[,2])
alldata
alldata$activity
test<-alldata$activity
alldata$activity<-factor(alldata$activity,levels = activityLabel[,1],labels = activityLabel[,2])
alldata$activity
alldata
?melt
library(reshape2)
?melt
allData$subject <- as.factor(allData$subject)
alldata.melted<-melt(alldata,id=c("subject","activity"))
allData$subject <- as.factor(allData$subject)
alldata.melted
alldata.melted<-melt(alldata,id=c("subject","activity"))
alldata.mean<-dcast(alldata.melted,subject+activity~variable,mean)
head(alldata.mean)
alldata.mean
write.table(allData.mean, "./tidy.txt", row.names = FALSE, quote = FALSE)
write.table(alldata.mean, "./tidy.txt", row.names = FALSE, quote = FALSE)
install.packages("reshape2")
library(reshape2)
#read activity_labels
activityLabel<-read.table("./UCI HAR Dataset/activity_labels.txt")
activityLabel[,2]<-as.character(activityLabel[,2])
#read features
features<-read.table("./UCI HAR Dataset/features.txt")
features[,2]<-as.character(features[,2])
#extract only mean and std
wantedFeature<-grep(".*mean.*|.*std.*",features[,2])
#use descriptive names for labels in datasets
wantedFeature.names<-gsub("-mean","Mean",wantedFeature.names)
wantedFeature.names<-gsub("-std","Std",wantedFeature.names)
wantedFeature.names<-gsub("[-()]","",wantedFeature.names)
# read train data
X_train <- read.table("./UCI HAR Dataset/train/X_train.txt")[wantedFeature]
install.packages("reshape2")
install.packages("reshape2")
library(reshape2)
#read activity_labels
activityLabel<-read.table("./UCI HAR Dataset/activity_labels.txt")
activityLabel[,2]<-as.character(activityLabel[,2])
#read features
features<-read.table("./UCI HAR Dataset/features.txt")
features[,2]<-as.character(features[,2])
#extract only mean and std
wantedFeature<-grep(".*mean.*|.*std.*",features[,2])
#use descriptive names for labels in datasets
wantedFeature.names<-gsub("-mean","Mean",wantedFeature.names)
wantedFeature.names<-gsub("-std","Std",wantedFeature.names)
wantedFeature.names<-gsub("[-()]","",wantedFeature.names)
# read train data
X_train <- read.table("./UCI HAR Dataset/train/X_train.txt")[wantedFeature]
Y_train <- read.table("./UCI HAR Dataset/train/Y_train.txt")
Sub_train <- read.table("./UCI HAR Dataset/train/subject_train.txt")
train<-cbind(Sub_train,Y_train,X_train)
# read test data
X_test <- read.table("./UCI HAR Dataset/test/X_test.txt")[wantedFeature]
Y_test <- read.table("./UCI HAR Dataset/test/Y_test.txt")
Sub_test <- read.table("./UCI HAR Dataset/test/subject_test.txt")
test<-cbind(Sub_test,Y_test,X_test)
#merge datasets
alldata<-rbind(train,test)
colnames(alldata)<-c("subject","activity",wantedFeature.names)
#use descriptive activity names for activities
alldata$activity<-factor(alldata$activity,levels = activityLabel[,1],labels = activityLabel[,2])
allData$subject <- as.factor(allData$subject)
alldata.melted<-melt(alldata,id=c("subject","activity"))
alldata.mean<-dcast(alldata.melted,subject+activity~variable,mean)
write.table(alldata.mean, "./tidy.txt", row.names = FALSE, quote = FALSE)
write.table(alldata.mean, "./tidy.txt", row.names = FALSE, quote = FALSE)
